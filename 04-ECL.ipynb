{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c260ce0-2c47-4bd4-9267-fdc940afe4a4",
   "metadata": {},
   "source": [
    "## Deploying PD, LGD, EAD models to calculate ECL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42404ae1-99b6-4a29-946d-fc5f889ede4d",
   "metadata": {},
   "source": [
    "In this notebook, we import the PD, LGD, and EAD models we developed in the first three notebooks to calculate the Expected Credit Loss (ECL):\n",
    "\n",
    "$$ECL = PD \\times LGD \\times EAD$$\n",
    "\n",
    "Importing the models will be done using the **pickle** package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f7a2a-2904-4153-a3e8-f73012b5786a",
   "metadata": {},
   "source": [
    "Let us import the libraries as well as the datasets for the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d53b0dbd-e61c-432e-bae4-1abdacb97ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f2361-34a2-4e2d-b66f-d7f80cff9638",
   "metadata": {},
   "source": [
    "## Importing and Matching Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e1543-5ce3-4663-ad74-874bc23cf3cc",
   "metadata": {},
   "source": [
    "For LGD and EAD, we only need to import the pre-processed raw datasets. For PD however, we need to import the dataset comprised of dummy variables we coarse-classed with Weight-of-Evidence calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb3bf32d-5865-4b19-9af6-35ef2eae9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data for LGD and EAD\n",
    "df_loans = pd.read_csv('loans_preprocessed.csv')\n",
    "\n",
    "# Loading the dataset for PD calculation\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6eab0-a83a-4f21-9ecc-fc0d5a69809b",
   "metadata": {},
   "source": [
    "As the dataset for PD is not only split, but also shuffled, we need to combine it and re-arrange it by the original index number in order for the data order to match that of LGD and EAD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "591752ba-59be-47c5-9faa-80453a385cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PD_data = pd.concat([X_train, X_test], axis = 0) # axis is 0 because we are combining rows\n",
    "PD_data = PD_data.set_index('Unnamed: 0') # Set the old index before exporting into index\n",
    "PD_data = PD_data.sort_index() # Sort data by new index to match LGD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344eab7-02f1-4874-92fe-19555b7adff0",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "## Loading and Running the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14698244-dcc3-4ebb-9974-42d7ac7ed062",
   "metadata": {},
   "source": [
    "We load our PD, LGD, and EAD models using the **pickle** package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd50cd8f-0c5f-41e3-a059-3aa9d0a1a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading the two PD model\n",
    "with open('PD_model.pkl', 'rb') as f:\n",
    "    PD_model = pickle.load(f)\n",
    "\n",
    "\n",
    "# Loading the two LGD models\n",
    "with open('RR_model.pkl', 'rb') as f:\n",
    "    RR_model_1 = pickle.load(f)\n",
    "\n",
    "with open('RR_model.pkl', 'rb') as f:\n",
    "    RR_model_2 = pickle.load(f)\n",
    "\n",
    "# Loading the two EAD_to_LoanAmt model\n",
    "with open('EAD_model.pkl', 'rb') as f:\n",
    "    EAD_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037bc441-d6a2-4f7a-894f-812e5112aa0d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Running the PD model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8cac97-0e67-4653-9268-3ad4733b7120",
   "metadata": {},
   "source": [
    "As with the PD modelling exercise, we need to drop reference categories and also add the intercept constant. We also need to drop dummy variables that were found to have no variance in the modelling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d15c4ed-e2d8-46bb-a229-236d45c03e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_categories = ['Grade:_A', 'home_ownership:_MORTGAGE', 'addr_state:_AL', 'verif:_Not Verified', 'purpose:_cred-card', \n",
    "                  'init_list_status:_f', 'term:_36', 'empLength: _(-inf, 0.0]', 'mths_sinc_issue:_(-inf, 0.0]', \n",
    "                  'int_rate: _(5, 10]', 'annual_inc: _0k-20k', 'DtI: _(8, 12]', 'mths_last_record: _(0.0, 70.0]']\n",
    "\n",
    "categ_no_variance = ['empLength: _(10.0, inf]', 'mths_last_record: _(130.0, inf]']\n",
    "\n",
    "\n",
    "PD_data_with_const = PD_data.drop(ref_categories + ['id'] + categ_no_variance, axis = 1)\n",
    "PD_data_with_const.insert(0, 'intercept', 1)\n",
    "PD_data_with_const['intercept'] = PD_data_with_const.intercept.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12b2c268-76b2-4e47-8064-808edd6db795",
   "metadata": {},
   "outputs": [],
   "source": [
    "PD_data_with_const['PD'] = PD_model.predict(PD_data_with_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f0c55cbe-4d2a-46d8-b5e1-deec08c6e817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    466285.000000\n",
       "mean          0.109210\n",
       "std           0.069475\n",
       "min           0.007092\n",
       "25%           0.057082\n",
       "50%           0.093949\n",
       "75%           0.145580\n",
       "max           0.660239\n",
       "Name: PD, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PD_data_with_const['PD'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cb3345-96e6-4e58-9268-e7d01fc1667f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Running the LGD model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a2c6a-191f-402a-9d82-ba3cb15c9519",
   "metadata": {},
   "source": [
    "For the LGD and EAD model:\n",
    "- Our model used a specific set of predictors which we need to filter out,\n",
    "- We need to add additional variables we added for our model like months since last payment,\n",
    "- We need to watch whether additional dummies exist that were not in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c87271b-8bfe-43c7-aacb-f72c396d9718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new variable containing the number of months between last_payment_date and end of 2014\n",
    "\n",
    "# Convert to datetime (the given year is two-digit and needs \"20\" prefix)\n",
    "df_loans['prop_last_pymnt_d'] = pd.to_datetime(df_loans['last_pymnt_d'], format='%b-%y')\n",
    "\n",
    "# Reference date is end of 2016\n",
    "ref_date = pd.to_datetime('2016-12-31')\n",
    "\n",
    "# Calculating the difference between ref-date and last payment date in months\n",
    "df_loans['last_payment_months'] = (ref_date.year - df_loans['prop_last_pymnt_d'].dt.year) * 12 + (ref_date.month - df_loans['prop_last_pymnt_d'].dt.month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d091c6f-4ce8-44d7-a0dc-5b3ef238d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_dummies = pd.get_dummies(df_loans.grade, drop_first = True, prefix = 'Grade: ')\n",
    "home_own_dummies = pd.get_dummies(df_loans.home_ownership, drop_first = True, prefix = 'Home_Own: ')\n",
    "verif_dummies = pd.get_dummies(df_loans.verification_status, drop_first = True, prefix = 'Verif_Status: ')\n",
    "\n",
    "# Drop additional dummy column that is not in the original model\n",
    "home_own_dummies = home_own_dummies.drop('Home_Own: _MORTGAGE', axis = 1)\n",
    "\n",
    "# Build a new dataframe with only selected features during the modeling exercise\n",
    "LGD_data = df_loans[['dti','funded_amnt', 'emp_length_int', 'term_int', 'last_payment_months',\n",
    "                  'mths_since_issue_d', 'mths_since_earliest_cr_line', 'mths_since_last_delinq', 'mths_since_last_record']]\n",
    "\n",
    "# Combining the selected variables with the dummies\n",
    "LGD_data = pd.concat([LGD_data, grade_dummies, home_own_dummies, verif_dummies], axis = 1)\n",
    "\n",
    "# Adding a constant for the intercept\n",
    "LGD_data.insert(0, 'intercept', 1)\n",
    "\n",
    "LGD_data = LGD_data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9bf6f-ebd4-4c83-9f23-7f77542114f6",
   "metadata": {},
   "source": [
    "In our modeling exercise, we modeled RR in a two staged approach:\n",
    "- The first was to find out whether the RR is zero or not,\n",
    "- The second was to estimate RR when it is not zero.\n",
    "\n",
    "We got the outcomes of the two models by simple multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b22bfe1-3254-4a65-987a-6999a36cc8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGD_data['RR'] = RR_model_1.predict(LGD_data) * RR_model_2.predict(LGD_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536de2ea-ff2f-4041-8cc7-515a773b943d",
   "metadata": {},
   "source": [
    "Now we ensure that our RR is capped by ceiled by 1 and floored by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "687b7a9b-ba87-41f5-b4f4-4226786b25eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    465909.000000\n",
       "mean          0.224808\n",
       "std           0.140297\n",
       "min           0.027092\n",
       "25%           0.133383\n",
       "50%           0.182091\n",
       "75%           0.265713\n",
       "max           1.000000\n",
       "Name: RR, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGD_data['RR'] = np.where(LGD_data['RR'] > 1, 1, LGD_data['RR']) # capping with 1\n",
    "LGD_data['RR'] = np.where(LGD_data['RR'] < 0, 0, LGD_data['RR']) # floor with 0\n",
    "\n",
    "LGD_data['RR'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d7107-ced5-429b-974e-e03e26a3375a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Finally, we calculate LGD as (1 - Recovery Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00cd9262-bc12-4dad-8ef4-099a89f50086",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGD_data['LGD'] = 1- LGD_data['RR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda1571-6456-403b-9af9-132962726eb1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Running the EAD model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b0cc0-c150-4405-b587-b2b0671fcebf",
   "metadata": {},
   "source": [
    "The EAD model will use exactly the same approach we used to build the LGD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7ac0507-a254-4975-9378-c96eec2b5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with model variables for EAD prediction\n",
    "df_EADtLA = df_loans[['dti','funded_amnt', 'emp_length_int', 'term_int', 'last_payment_months',\n",
    "                  'mths_since_issue_d', 'mths_since_earliest_cr_line', 'mths_since_last_delinq', 'mths_since_last_record']]\n",
    "\n",
    "# Combining the dataframe with the dummies\n",
    "df_EADtLA = pd.concat([df_EADtLA, grade_dummies, home_own_dummies, verif_dummies], axis = 1)\n",
    "\n",
    "# Adding the intercept term\n",
    "df_EADtLA.insert(0, 'intercept', 1)\n",
    "\n",
    "df_EADtLA = df_EADtLA.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110f62c-2a36-4e57-a576-3d524f267039",
   "metadata": {},
   "source": [
    "Our model predicts the ratio of EAD_to_LoanAmount where:\n",
    "\n",
    "EAD = EAD_to_loanAmt_Ratio * Funded_Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63f5c5e7-ebe5-4078-94cd-3913db8e726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EADtLA['EAD'] = EAD_model.predict(df_EADtLA)* df_EADtLA['funded_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8114cbd5-6597-4f8a-9637-d20f9a2a46f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    465909.000000\n",
       "mean       8623.412424\n",
       "std        6750.774875\n",
       "min          27.046344\n",
       "25%        3363.904911\n",
       "50%        6793.658014\n",
       "75%       12212.351937\n",
       "max       34100.283372\n",
       "Name: EAD, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_EADtLA['EAD'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bce460-22cc-43ad-97da-af2a577e3865",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Calculating Expected Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de4407-4b4b-4b5c-a310-2118d7d00fcc",
   "metadata": {},
   "source": [
    "Finally, we combine the predicted outcomes from the three models to calculate ECL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df438c71-9c47-4331-ad7e-5a6152a800a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECL = pd.concat([df_EADtLA['EAD'], LGD_data['LGD'], PD_data_with_const['PD']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "110ee88b-458a-490f-bf4a-f60f7ed49480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAD</th>\n",
       "      <th>LGD</th>\n",
       "      <th>PD</th>\n",
       "      <th>ECL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648.558584</td>\n",
       "      <td>0.735352</td>\n",
       "      <td>0.165949</td>\n",
       "      <td>79.144211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2088.752571</td>\n",
       "      <td>0.495362</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>202.902774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>612.660205</td>\n",
       "      <td>0.605356</td>\n",
       "      <td>0.174473</td>\n",
       "      <td>64.708036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361.896480</td>\n",
       "      <td>0.677487</td>\n",
       "      <td>0.179584</td>\n",
       "      <td>165.696639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301.308581</td>\n",
       "      <td>0.777915</td>\n",
       "      <td>0.111307</td>\n",
       "      <td>26.089466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           EAD       LGD        PD         ECL\n",
       "0   648.558584  0.735352  0.165949   79.144211\n",
       "1  2088.752571  0.495362  0.196100  202.902774\n",
       "2   612.660205  0.605356  0.174473   64.708036\n",
       "3  1361.896480  0.677487  0.179584  165.696639\n",
       "4   301.308581  0.777915  0.111307   26.089466"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating ECL\n",
    "df_ECL['ECL'] = df_ECL.PD * df_ECL.LGD * df_ECL.EAD\n",
    "\n",
    "df_ECL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8add8be3-d662-4676-bd99-1568ea5318aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Expected Loss: 320,718,386\n",
      "Percentage of Expected Loss to Total Portfolio is: 0.0481\n"
     ]
    }
   ],
   "source": [
    "# The total expected loss at the portfolio level\n",
    "total_ECL = df_ECL['ECL'].sum()\n",
    "print(f'Total Expected Loss: {total_ECL:,.0f}')\n",
    "\n",
    "total_funded_amount = df_loans['funded_amnt'].sum()\n",
    "print(f'Percentage of Expected Loss to Total Portfolio is: {total_ECL/total_funded_amount:,.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
